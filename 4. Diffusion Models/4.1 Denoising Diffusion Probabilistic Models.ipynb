{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72425a37",
   "metadata": {},
   "source": [
    "# Diffusion Models\n",
    "## Background\n",
    "![diff](../resources/images/diff.png)\n",
    "\n",
    "Starting with our original data - a conspicuously llama-shaped cloud, $x_0$, sampled from a true underlying distribution, $q$:\n",
    "$$x_0 \\sim q_\\text{data}(x)$$\n",
    "\n",
    "We see in the above image how the distribution of data at each subsequent step is dependent on the current step: the cloud-shaped llama at $t+1$ is a slightly distorted version of the cloud-shaped llama at time $t$. In other words, the evolution of the distribution is such that the state at $t+1$ depends only on the state at time $t$ - i.e., $q(x_t|x_{t-1})$. Under this assumption, the process is **Markovian**. Each perturbation step is governed by a **Markov transition kernel**, $K(x_{t+1}|x_t)$ which specifies a conditional distribution over possible next states given the current state by marginalising over all possible previous states:\n",
    "$$q(x_{t+1})=\\int K(x_{t+1}|x_t)\\cdot q(x_t)\\text{ }dx_t$$\n",
    "When this stochastic transition is applied across the data distribution, the uncertainty it introduces leads to a gradual smoothing of the density function, destroying the fine structure in the data and causing the distribution to become increasingly diffuse. We therefore define the **forward process** as \n",
    "$$x_{t+1}\\sim K(x_{t+1}|x_t).$$\n",
    "\n",
    "So far, we have described the forward dynamics of a diffusion process: a Markovian evolution that progressively and irreversibly destroys fine-scale structure in the data. Nevertheless, one might observe that if the correspond **reverse-time dynamics** could be modelled, then the diffusion process could be repurposed as a generative model: by starting from a simple, highly diffused distribution, samples could progressively be transformed back into realistic data by simulating this reverse process. This requires three ingredients:\n",
    "1. A simple, known distribution that approximates the terminal state of the forward process;\n",
    "2. A reverse-time transition kernel that describes how samples evolve backwards through time; \n",
    "3. and a learnable parameterisation of the reverse-time dynamics.\n",
    "\n",
    "In practice, we will choose a simple reference distribution, $p_T(x)$, that is easy to sample from. The forward process is defined, through the choice of kernel and its hyperparameters, so that after enough steps, $x_T$ is approximately distributed according to this reference distribution:\n",
    "$$q(x_T)\\approx p_T(x)$$\n",
    "Most commonly, an isotropic Gaussian, $p_T(x)=N(0, I)$, is chosen as  the reference distribution. Put simply, we progressively corrupt the data until it resembles Gaussian noise.\n",
    "\n",
    "Next, we need a reverse-time transition kernel, $x_{t-1}\\sim T(x_{t-1}|x_t)$, that will evolve our reference distribution $p$:\n",
    "$$p_{t-1}(x_{t-1})=\\int T(x_{t-1}|x_t)\\cdot p_T(x_t)\\text{ }dx_t$$\n",
    "This is easier said than done. To see why, we can derive it explicitly from the forward process. \n",
    "\n",
    "If the reverse process is to exactly invert the forward process in distribution, then its transitions need to match the conditional distribution induced by the forward dynamics. Therefore, the reverse-time transition kernel must be equal to the reverse conditional of the forward process:\n",
    "$$T(x_{t-1}|x_t)=q(x_{t-1}|x_t)$$\n",
    "\n",
    "To obtain that, we can use the definition of a conditional distribution:\n",
    "$$q(x_{t-1}|x_t)=\\frac{q(x_{t-1}, x_t)}{q(x_t)}$$\n",
    "\n",
    "To obtain the joint distribution $q(x_{t-1}, x_t)$, we first re-visit our forward process. The joint distribution across an entire forward trajectory $x_{0:T}$ factorises as\n",
    "$$q(x_{0:T})=q(x_0)\\prod_{t=1}^T K(x_t|x_{t-1})$$\n",
    "By taking that result, we can marginalise out everything except $(x_{t-1}, x_t)$ to give:\n",
    "$$q(x_{t-1}, x_t) = q(x_{t-1}) \\cdot K(x_t|x_{t-1})$$\n",
    "Substituting back into our earlier expression, we can yield a definition for our reverse-time transition kernel:\n",
    "$$q(x_{t-1}|x_t)=\\frac{q(x_{t-1}) \\cdot K(x_t|x_{t-1})}{q(x_t)}$$\n",
    "While the forward kernel $K$ is known (we define it), the intermediate marginals $q(x_{t-1})$ and $q(x_t)$ are only defined through repeated application of the forward process to real data. Since the data distribution $q(x_0)$ is unknown and accessible only through samples - i.e., we do not know its functional form - the intermediates cannot be evaluated pointwise, meaning that for a given value $\\tilde{x_t}$, we cannot compute $q(x_t=\\tilde{x_t})$ (the marginal density of $x_t$) and consequently the conditional $q(x_{t-1}|x_t=\\tilde{x_t})$.  Thus, the true reverse-time kernel is intractable. What can we do instead?\n",
    "\n",
    "Diffusion models address this by introducing a parameterised approximation $p_\\theta(x_{t-1}|x_t)$ to the intractable reverse-time kernel, which is trained to match the true reverse dynamics induced by the forward process.\n",
    "$$p_\\theta(x_{t-1}|x_t)\\approx q(x_{t-1}|x_t)=\\frac{q(x_{t-1}) \\cdot K(x_t|x_{t-1})}{q(x_t)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad5b7d4",
   "metadata": {},
   "source": [
    "## Approximating the Reverse-Time Kernel\n",
    "Let's begin by specifying the forward process kernel $K(x_{t+1}|x_t)$. As discussed earlier, the role of the forward process is to progressively corrupt the data distribution until it approximately resembles a simple reference distribution. For this reference distribution to be useful in a generative setting, it should be known, tractable, and easy to sample from.\n",
    "\n",
    "The standard multivariate Gaussian emerges as a natural choice. Accordingly, we design the forward process such that after sufficiently many steps, the marginal distribution of $x_T$ is approximately\n",
    "$$q(x_T)\\approx \\mathcal{N}(0,I).$$\n",
    "\n",
    "To do this, we define a forward transition kernel that slowly corrupts the current state with Gaussian noise at each step. We must consider that:\n",
    "1. We want to inject noise at each step;\n",
    "2. and the scale of $x_T$ must be controlled.\n",
    "The second point requires that while we **add** noise to $x_t$, we must also gradually **attenuate** it too. Without attenuation, noise would accumulate across steps leading to a random walk that takes us far from the fixed end-point we had hoped to eventually sample from. \n",
    "\n",
    "A simple forward kernel that satisfies these criteria can be written in the linear Gaussian form:\n",
    "$$x_{t}=ax_{t-1} + b\\epsilon_t, \\quad \\epsilon\\sim\\mathcal{N}(0,I)$$\n",
    "where $a$ and $b$ are constants that control attenuation and noise injection respectively. At each step, some of the original signal is removed and an amount of noise is added.\n",
    "\n",
    "To ensure that the standard Gaussian distribution is a stable fixed point of the forward process, we require that if $x_{t-1}\\sim\\mathcal{N}(0,I)$, then the resulting variable $x_t$ is also distributed as $\\mathcal{N}(0,I)$. Under this condition, the variance of $x_t$ \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(x_t)&=\\text{Var}(ax_{t-1}+b\\epsilon_t)\\\\\n",
    "&=a^2\\text{Var}(x_{t-1})+b^2\\text{Var}(\\epsilon_t)\\\\\n",
    "&=a^2+b^2,\n",
    "\\end{align}\n",
    "$$\n",
    "satisfies (recalling that the standard Gaussian has a variance of 1) the constraint\n",
    "$$a^2+b^2=1$$\n",
    "and so\n",
    "$$\n",
    "\\begin{align}\n",
    "a=\\sqrt{1-b^2}\\\\\n",
    "b=\\sqrt{1-a^2}\n",
    "\\end{align}\n",
    "$$\n",
    "In practice, we define a single scalar for both $a$ and $b$, referred to as $\\beta$:\n",
    "$$\n",
    "a=\\sqrt{1-\\beta},\\quad\n",
    "b=\\sqrt{\\beta}.\n",
    "$$\n",
    "\n",
    "Thus, we yield the final parameterisation of the forward step:\n",
    "$$x_t=\\sqrt{1-\\beta}\\cdot x_{t-1}+\\sqrt{\\beta}\\cdot \\epsilon_t,\\quad\\epsilon\\sim\\mathcal{N}(0,I)$$\n",
    "This implicitly defines our forward kernel:\n",
    "$$K(x_{t}|x_{t-1})=\\mathcal{N}(\\sqrt{1-\\beta}x_{t-1}, \\beta_t I).$$\n",
    "\n",
    "While this forward kernel specifies how noise is injected locally at each step, it does not describe the cumulative effect of repeatedly applying this process. In particular, it does not by itself explain how successive transitions transform a complex data-generating distribution into a simple multivariate Gaussian. \n",
    "\n",
    "To understand how the forward diffusion behaves globally, we can examine how a noisy state at an arbitrary time step $x_t$ relates to the original data point $x_0$. Doing so will allow us to describe the effect of the forward process after $t$ steps in a single expression without simulating intermediate transitions - i.e., it allows us to reason about the conditional distribution $q(x_t|x_0)$. \n",
    "\n",
    "Importantly, this gives us insight into the forward process *irrespective of any intractable data distributions*. This switches the question from 'What does the data look like after corruption?' ($q(x_t)$ - intractable) to 'What happens to a specific data point when I corrupt it?' ($q(x_t|x_0)$ - tractable). Once we begin to understand this relationship, we can begin to reason about how such corruption may be systematically undone. \n",
    "\n",
    "Using a Gaussian kernel allows us to do something interesting. Any linear transformation of a Gaussian distribution is itself Gaussian. That means that we can sample $x_t$ at an arbitrary timestep $t$ in closed form. \n",
    "\n",
    "Firstly, we define\n",
    "$$\\alpha \\doteq 1-\\beta,$$\n",
    "and the cumulative product\n",
    "$$\\bar{\\alpha}_t\\doteq \\prod_{s=1}^t \\alpha_s.$$\n",
    "We can then begin to unroll our Markov chain. For $t=1$:\n",
    "$$x_1=\\sqrt{\\alpha_1}x_0+\\sqrt{1-\\alpha_1}\\epsilon_1$$\n",
    "Substituting into $t=2$:\n",
    "$$\n",
    "\\begin{align}\n",
    "x_2=\\sqrt{\\alpha_2}(\\sqrt{\\alpha_1}x_0+\\sqrt{1-\\alpha}\\epsilon_1)+\\sqrt{1-\\alpha_2}\\epsilon_2\\\\\n",
    "x_2=\\sqrt{\\alpha_2\\alpha_1}x_0 + \\underbrace{\\sqrt{\\alpha_2(1-\\alpha_1)}\\epsilon_1 + \\sqrt{1-\\alpha_2}\\epsilon_2}_{\\text{Sum of Gaussians}}\n",
    "\\end{align}\n",
    "$$\n",
    "Note that the coefficient on $x_0$ is $\\sqrt{\\alpha_1\\alpha_2}=\\sqrt{\\bar{\\alpha}_2}$, and the noise is now a sum of differently-scaled independent Gaussians. This gives us the obvious generalised coefficient for $x_0$, $\\sqrt{\\bar{\\alpha}_t}$, and the noise coefficient $\\sqrt{1-\\bar{\\alpha}_t}$. With this information, we can generate $x_t$ at an arbitrary timestep:\n",
    "$$x_t=\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon$$\n",
    "\n",
    "Earlier, we proposed that a generative model could be defined by reversing the noising process. Given the forward transition $q(x_t|x_{t-1})$, we would like to compute the corresponding reverse conditional $q(x_{t-1}|x_t)$ - that is, what data at time $t-1$ could have reasonably produced the observed noisy sample $x_t$. We also discussed how this reverse distribution was intractable because it depends on the marginal density $q(x_t)$, which is defined implicitly through the unknown data-generating distribution $q(x_0)$. \n",
    "\n",
    "However - what if we *did* have a sample from $q(x_0)$? If we had access to the original data, and we see what the noised version looks like at time $t$, could we reason about what it could have looked like at time $t-1$? As it transpires, under the Gaussian forward process, this conditional distribution $q(x_{t-1}|x_t, x_0)$ *is* analytically tractable.\n",
    "\n",
    "Conditioning on the original data point $x_0$ transforms the problem into a simple linear-Gaussian inference task. Under the forward process, $x_{t-1}$ is obtained by a linear transformation plus Gaussian noise, and $x_t$ is obtained from $x_{t-1}$ by another linear Gaussian transformation. As a result, the joint distribution of $(x_{t-1}, x_t$ conditioned on $x_0$ is a multivariate Gaussian, and so it follows that the conditional distribution $q(x_{t-1}|x_t, x_0)$, obtained by conditioning one Gaussian variable on another, is itself Gaussian. \n",
    "\n",
    "A standard property of Gaussian conditioning is that the conditional mean is an affine function of the variables being conditioned on. Consequently, the mean of $q(x_{t-1}|x_t, x_0)$, $\\tilde{\\mu}_t$ is a linear combination of the noisy sample $x_t$ and the original data point $x_0$. Since the covariance is fully specified by the noise schedule, the corresponding conditional variance $\\tilde{\\beta}_tI$ is a deterministic function of that schedule. Thus we can construct:\n",
    "$$q(x_{t-1}|x_t, x_0)=\\mathcal{N}(\\tilde{\\mu}_t(x_t, x_0), \\tilde{\\beta}_t I)$$\n",
    "\n",
    "The closed-form expressions for both the posterior mean $\\tilde{\\mu}_t$ and variance $\\tilde{\\beta}_t$ can readily be derived by virtue of Gaussian algebra to yield:\n",
    "$$\n",
    "\\tilde{\\mu}_t(x_t, x_0)=\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t + \\frac{\\beta_t\\sqrt{\\bar{\\alpha}_{t-1}}}{1-\\bar{\\alpha}_t}x_0, \\quad\n",
    "\\tilde{\\beta}_t = \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\beta_t.\n",
    "$$\n",
    "\n",
    "An observant reader may note that while this construction allows us to derive an exact reverse transition given access to the original data point $x_0$, the purpose of a generative model is precisely to produce new samples for which no such data point exists. At generation time, we observe only the noisy sample $x_t$, and the conditional distribution $q(x_{t-1}|x_t, x_0)$ cannot be evaluated directly. \n",
    "\n",
    "However, we have identified a tractable conditional distribution that characterises the true reverse dynamics of the diffusion process when the original data point is known. The remaining question, then, is how to construct a generative model that can approximate these dynamics *without access to $x_0$*.\n",
    "\n",
    "The original diffusion formulation, proposed by Sohl-Dickstein et al., introduced a parameterised reverse-time Markov kernel\n",
    "$$p_\\theta(x_{t-1}|x_t),$$\n",
    "and trained it to match the analytically defined conditional $q(x_{t-1}|x_t, x_0)$ by minimising a KL divergence, averaged over data and forward trajectories. In the case of a Gaussian forward kernel, this corresponds to predicting a learned mean $\\mu_\\theta(x_t, t)$ and covariance of the reverse transition directly.\n",
    "\n",
    "Ho et al. make a crucial simplifying observation: since the analytic reverse-step distribution is known up to its dependence on $x_0$, there is no need to learn the reverse dynamics from scratch. We can instead learn to predict $x_0$ itself from the noisy sample $x_t$, and then construct the reverse transition analytically using this prediction. Concretely, Ho et al. replace $x_0$ in $\\tilde{\\mu}_t(x_t, x_0)$ with a learned prediction $\\hat{x}_0(x_t, t)$ and define the reverse-process mean by\n",
    "$$\\mu_\\theta(x_t, t)\\doteq \\tilde{\\mu}_t\\left(x_t, \\hat{x}_0(x_t, t)\\right).$$\n",
    "The reverse-time model is then parameterised as\n",
    "$$p_\\theta(x_{t-1}|x_t)=\\mathcal{N}\\left(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)\\right),$$\n",
    "where $\\Sigma_\\theta$ is often fixed to a value derived from the schedule such as $\\tilde{\\beta}_tI$ or $\\beta_tI$ rather than learning it.\n",
    "\n",
    "We can then use a function approximator (in this case, a neural network) to predict $\\hat{x}_0$ given $x_t$ and $t$ as input, and then calculate the posterior mean as follows:\n",
    "$$\\mu_\\theta(x_t, t)=\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t + \\frac{\\beta_t\\sqrt{\\bar{\\alpha}_{t-1}}}{1-\\bar{\\alpha}_t}\\hat{x}_0(x_t, t),$$\n",
    "\n",
    "To consider how this network will be trained, let's revisit the original objective - approximating the reverse-time kernel:\n",
    "$$p_\\theta(x_{t-1}|x_t)\\approx q(x_{t-1}|x_t, x_0)$$\n",
    "\n",
    "We want the distribution of our kernel to approach that of the true reverse-time kernel by adjusting the parameters $\\theta$. Naturally, minimising the Kuhlback-Leiber divergence (KL) between our model and the true underlying presents a reasonable objective:\n",
    "$$\\mathcal{L}(\\theta)\\doteq\\mathbb{E}_{t\\sim\\text{Uniform}\\set{1,...,T}, x_0\\sim q_\\text{data}, \\epsilon\\sim\\mathcal{N}(0,I)}\\left[\\text{KL}\\left(q(x_{t-1}|x_t, x_0)||p_\\theta(x_{t-1}|x_t)\\right)\\right]$$\n",
    "\n",
    "A standard identity of the KL divergence between two Gaussian distributions with the same covariance is such that\n",
    "$$KL\\left(\\mathcal{N}(\\mu_q, \\Sigma) || \\mathcal{N}(\\mu_p, \\Sigma)\\right) = \\frac{1}{2}(\\mu_p - \\mu_q)^\\intercal\\Sigma^{-1}(\\mu_p-\\mu_q)$$\n",
    "where $\\Sigma=\\tilde{\\beta}_tI$ is fixed by the noise schedule, and $d$, the dimensionality, is fixed. \n",
    "\n",
    "Where $\\Sigma^{-1}=\\frac{1}{\\tilde{\\beta}_t}I$, $\\mu_q=\\tilde{\\mu}_t(x_t, x_0)$, and $\\mu_p=\\mu_\\theta(x_t, t)$, we can then define our objective function as follows:\n",
    "$$\\mathcal{L}(\\theta)=\\mathbb{E}\\left[\\frac{1}{2\\tilde{\\beta}_t}||\\mu_\\theta(x_t, t)-\\tilde{\\mu}_t(x_t, x_0)||^2\\right]$$\n",
    "\n",
    "Given that we know:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tilde{\\mu}_t(x_t, x_0)=A_tx_0 + B_tx_t \\\\\n",
    "\\mu_\\theta(x_t, t)=A_t\\hat{x}_0(x_t, t) + B_tx_t\n",
    "\\end{align}\n",
    "$$\n",
    "Then we can take the difference as:\n",
    "$$\n",
    "\\mu_\\theta-\\tilde{\\mu}_t=A_t(\\hat{x}_0-x_0)+B_tx_t - B_tx_t = A_t(\\hat{x}_0-x_0)\n",
    "$$\n",
    "And therefore our loss becomes:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta)&=\\mathbb{E}\\left[\\frac{1}{2\\tilde{\\beta}_t}||A_t(\\hat{x}_0(x_t, t)-x_0)||^2\\right]\\\\\n",
    "&=\\mathbb{E}\\left[\\underbrace{\\frac{A^2_t}{2\\tilde{\\beta}_t}}_{w_t}||\\hat{x}_0(x_t, t)-x_0||^2\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "Ho et al. observe empirically that the time-dependent weight $w_t$ leads to degraded sample quality, and so this term is generally dropped to yield a simplified objective\n",
    "$$\\mathcal{L}(\\theta)=E\\left[||\\hat{x}_0(x_t, t)-x_0||^2\\right]$$\n",
    "However, let us now consider why predicting $x_0$ directly may be a poorly conditioned objective. Consider trying to predict an original image, $x_0$, with two separate noised samples - one at $t+1$ (one denoising step) and one at $t=T$ (terminal denoising step). With only a small amount of noise, $x_t$ still retains substantial information about $x_0$, and the associated uncertainty is low - the conditional $q(x_0|x_t)$ is sharply concentrated. Errors in predicting $x_0$ here reflect meaningful discrepancies between the model's estimate and the true data. \n",
    "\n",
    "Howver, when $t$ is large and $x_t$ is dominated by noise, very little of the signal from the original image is retained and the associated uncertainty is very high - $q(x_0|x_t)$ is very broad as many clean images are consistent with the same noisy sample. Errors in predicting $x_0$ at this level therefore arise largely from intrinsic uncertainty rather than from deficiencies in the model. \n",
    "\n",
    "Our regression objective, however, treats these prediction errors at both high and low noise as equally informative. This forces our model to devote capacity to resolving ambiguous predictions at large $t$ while assigning no special importance to errors in regimes where the signal is strong and errors are informative. As a result, optimisation becomes poorly conditioned as gradients are dominated by high-variance and low-information errors. While this could be resolved by introducing error weighting according to $t$, Ho et al. propose another solution. \n",
    "\n",
    "Let's re-visit the equation for generating $x_t$ at an arbitrary timestep given $x_0$:\n",
    "$$x_t=\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon, \\quad\\epsilon\\sim\\mathcal{N}(0, I)$$\n",
    "\n",
    "We can consider another parameterisation of this process.\n",
    "$$x_0=\\frac{1}{\\sqrt{\\bar{\\alpha}_t}}(x_t-\\sqrt{1-\\bar{\\alpha}_t}\\epsilon$$\n",
    "We can then substitute this value into the analytic posterior mean we derived earlier to yield\n",
    "$$\\tilde{\\mu}_t(x_t, x_0)=\\frac{1}{\\sqrt\\alpha_t}\\left(x_t-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon\\right)$$\n",
    "Then, we can instead define our model to predict the noise, $\\hat{\\epsilon}_\\theta(x_t, t)$, and parameterise the mean of our reverse kernel $p_\\theta(x_{t-1}|x_t)$:\n",
    "$$\\mu_\\theta(x_t, t)=\\frac{1}{\\sqrt\\alpha_t}\\left(x_t-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\hat{\\epsilon}_\\theta(x_t, t)\\right)$$\n",
    "Recalling that we earlier derived our KL objective to be $\\mathcal{L}(\\theta)=\\mathbb{E}\\left[\\frac{1}{2\\tilde{\\beta}_t}||\\mu_\\theta(x_t, t)-\\tilde{\\mu}_t(x_t, x_0)||^2\\right]$, we can recalculate the means in the epsilon form:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_\\theta-\\tilde{\\mu}_t&=\\frac{1}{\\sqrt{a_t}}\\left(-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\hat{\\epsilon}_\\theta + -\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon\\right)\\\\\n",
    "&= \\frac{\\beta_t}{\\sqrt{\\alpha_t}\\sqrt{1-\\bar{\\alpha}_t}}(\\epsilon-\\hat{\\epsilon}_\\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "Therefore, we have\n",
    "$$||\\mu_\\theta-\\tilde{\\mu}_t||^2=\\frac{\\beta_t^2}{a_t(1-\\bar{\\alpha}_t)}||\\epsilon-\\hat{\\epsilon}_\\theta(x_t,t)||^2$$\n",
    "Substituting back into our objective to obtain:\n",
    "$$\n",
    "\\mathcal{L}(\\theta)=\\mathbb{E}\\left[\\frac{\\beta_t^2}{2\\tilde{\\beta}_t\\alpha_t(1-\\bar{\\alpha}_t)}||\\epsilon-\\hat{\\epsilon}_\\theta(x_t,t)||^2\\right]\n",
    "$$\n",
    "Similarly to earlier, the scalar coefficient is often dropped in practice to yield the simplified loss:\n",
    "$$\\mathcal{L}(\\theta)=\\mathbb{E}\\left[||\\epsilon-\\hat{\\epsilon}_\\theta(x_t,t)||^2\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cccc96",
   "metadata": {},
   "source": [
    "### References\n",
    "- Ho, J. et al. (2020). Denoising Diffusion Probabilistic Models ([arxiv](https://arxiv.org/abs/2006.11239))\n",
    "- Murphy, K. P. (2023). Probabilistic Machine Learning: Advanced Topics, Chapter 25: Diffusion Models ([MIT Press](https://probml.github.io/pml-book/book2.html))\n",
    "- Sohl-Dickstein, J. et al. (2015). Deep Unsupervised Learning using Nonequilibrium Thermodynamics ([arxiv](https://arxiv.org/abs/1503.03585))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
